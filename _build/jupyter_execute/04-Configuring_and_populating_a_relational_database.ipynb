{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "applicable-float",
   "metadata": {},
   "source": [
    "# Configuring and populating a relational database\n",
    "\n",
    "In this tutorial we introduce how to use [SQLite](https://en.wikipedia.org/wiki/SQLite) in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-stable",
   "metadata": {},
   "source": [
    "## SQLite\n",
    "\n",
    "[SQLite](https://www.sqlite.org) is a relational database management system (RDBMS) which can be embedded into the end program and does not follow a classic clientâ€“server architecture, where the server database is independent and is actually accessed by client programs.\n",
    "\n",
    "Python includes [SQLite within its standard library](https://docs.python.org/3/library/sqlite3.html) - it means that you can create and modify SQLite database directly from Python code. This simplifies a lot the first approach to DBMS, as we will see in the following sections. In addition, there are already several [documents on how to use SQLite in Python](https://www.digitalocean.com/community/tutorials/how-to-use-the-sqlite3-module-in-python-3) that are worth of reading to get more details about the features it provides. In this tutorial, we will see the main constructs used to create a database and populate it with tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-integer",
   "metadata": {},
   "source": [
    "## Create a new database\n",
    "\n",
    "First of all, we have to import functions defined in the [`sqlite3` package](https://docs.python.org/3/library/sqlite3.html) in order to use its classes to create and execute operations on a database. The first thing we need, in particular, is to use the [class `Connection`](https://docs.python.org/3/library/sqlite3.html#sqlite3.Connection). This class is responsible to connect to a particular database defined as a file. In SQLite, any database is actually stored in one single `.db` file. A new object having class `Connection` is created by calling the [function `connect`](https://docs.python.org/3/library/sqlite3.html#sqlite3.connect), as shown as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technical-collect",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlite3 import connect\n",
    "\n",
    "with connect(\"publications.db\") as con:\n",
    "    # do some operation with the new connection\n",
    "    \n",
    "    con.commit()  # commit the current transaction to the database\n",
    "    \n",
    "    # when you finish, the collection will be closed automatically via 'with'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-filling",
   "metadata": {},
   "source": [
    "As you can see, the way we use a new connection to a database is similar to what we have seen with files in previous tutorials, using the instruction `with` that allows us to close the connection to the database when all the operations with it have been executed. Before closing the connection, though, it is crucial to run the [method `commit`](https://docs.python.org/3/library/sqlite3.html#sqlite3.Connection.commit) in order to commit the current [transaction](https://en.wikipedia.org/wiki/Database_transaction) (i.e. the set of operations that may have changed the status of a database) to the database itself. Of course, it is possible to call the method `commit` more than once during the lifespan of a connection. In practice, you can call it every time you execute an operation that modifies the status of the database, in order to record such modification into the file system.\n",
    "\n",
    "It is worth mentioning that the `.db` file specifed as input of the function `connect` is created if no database is available with that name in the path specified. However, if such a file already exists, it will be loaded by the connection with the information it already stores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-senator",
   "metadata": {},
   "source": [
    "## From a diagram to tables\n",
    "\n",
    "Before starting populating the database, it is necessary to create the appropriate tables that enable the description of all the entities (and related data) we need. In order to understand what to do, it is important to look at the UML diagram describing the data model introduced in a previous tutorial.\n",
    "\n",
    "![UML diagram of a data model](../02/uml.png)\n",
    "\n",
    "There are different strategies that we can follow to crete the tables describing a data model such as that deiscribed above. For instance, we can approach such a translation as follows:\n",
    "\n",
    "* Create a table for each class which does not have any subclass (i.e. the most concrete classes), by using as columns all single-valued attributes and relations defined in such a class and all its superclasses. Concretely, we create four tables, i.e. for `JournalArticle` and `BookChapter` (which inherit all the attributes and relations of `Publication`), and `Journal` and `Book` (which inherit all the attributes and relations of `Venue`).\n",
    "\n",
    "* For each of the tables above, add also a new column that enables us to specify an internal identifier we use to clearly identify all the entities of the various types. In this case, it is enough to add an additional column in each table, e.g. `internalId`. Suggestion: having an internal identifier which is globally unique in the database is the way to go.\n",
    "\n",
    "* Keep in mind that the value of all the columns related to relations must point to an internal identifier defined in some of the tables. For instance, the column `publicationVenue` in the table `JournalArticle` will contain an internal identifier of a journal as defined in the column `internalId` of the table `Journal`.\n",
    "\n",
    "* Create a two column table, where the first column enables the identification of an internal identifier of an entity specified in the other tables, for each multivalued attribute or relation in the diagram. In the example, only the attribute `id` of the class `Venue` is multivalued, and thus an additional table `VenueId` is created to link a `Venue` entity with one or more identifiers characterising it.\n",
    "\n",
    "A possible translation of the UML diagram above following the rules just mentioned is shown as follows:\n",
    "\n",
    "![tables to represent the data model mentioned above](../04/tables.png)\n",
    "\n",
    "It is worth mentioning that this is not the only possible way to translate the original UML data mode, and other paths can be followed to this respect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-virtue",
   "metadata": {},
   "source": [
    "## How to create and populate a table with Pandas\n",
    "\n",
    "Pandas makes available specific methods that simplify the creation and population of database tables via `DataFrame`, and that take care also of running some database-related operations such as the `commit` shown above. The main tool to use to push a table into a SQLite database is the [method `to_sql`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html) of the class `DataFrame`. However, before seen how to use it to populate a database, let us reorganise the original data provided in CSV about publications and venues in a series of Pandas data frames recalling the tabular structures introduced in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-aurora",
   "metadata": {},
   "source": [
    "### Venue-Id table\n",
    "\n",
    "Let us start by creating the `VenueId` table. This can be done using one of the columns of the [CSV document describing venues](\"../01/01-venues.csv\"), i.e. the column `id`. Thus, we create a new sub-data frame containing only that column and we add an additional column defining the strings referring to the internal identifiers of each venue. The following code shows how to perform all these operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hired-anaheim",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_csv, Series\n\u001b[1;32m      3\u001b[0m venues \u001b[38;5;241m=\u001b[39m read_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../01/01-venues.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m                   keep_default_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m                   dtype\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m                   })\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# This will create a new data frame starting from 'venues' one,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# and it will include only the column \"id\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv, Series\n",
    "\n",
    "venues = read_csv(\"../01/01-venues.csv\", \n",
    "                  keep_default_na=False,\n",
    "                  dtype={\n",
    "                      \"id\": \"string\",\n",
    "                      \"name\": \"string\",\n",
    "                      \"type\": \"string\"\n",
    "                  })\n",
    "\n",
    "# This will create a new data frame starting from 'venues' one,\n",
    "# and it will include only the column \"id\"\n",
    "venues_ids = venues[[\"id\"]]\n",
    "\n",
    "# Generate a list of internal identifiers for the venues\n",
    "venue_internal_id = []\n",
    "for idx, row in venues_ids.iterrows():\n",
    "    venue_internal_id.append(\"venue-\" + str(idx))\n",
    "\n",
    "# Add the list of venues internal identifiers as a new column\n",
    "# of the data frame via the class 'Series'\n",
    "venues_ids.insert(0, \"venueId\", Series(venue_internal_id, dtype=\"string\"))\n",
    "\n",
    "# Show the new data frame on screen\n",
    "venues_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-finish",
   "metadata": {},
   "source": [
    "In practice, after reading the CSV, we create a new data frame with only the column `id` by using the command `<data frame>[[<column name 1>, <column name 2>, ...]]`. In practice, this command will create a new sub-data frame using only the values in the columns specified.\n",
    "\n",
    "Then, we have to define the internal identifiers for all the venues. To this end, we iterate over the rows of the new data frame and we compose a list of internal identifiers by concatenating the string `\"venue-\"` with the string of the values specified in the index of each row. Thus, we add that list (mediated via a `Series` of string values) into the data frame using the [method `insert`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.insert.html), which takes in input the position where to put the new column (`0` is the first position, `1` is the second position, etc.), the column name, and the values to associate to that column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-edmonton",
   "metadata": {},
   "source": [
    "### Tables for journals and books\n",
    "\n",
    "With this new table, we can start to create the two additional tables for journals and books. First of all, we create two new data frames containing only entities (i.e. rows) of the same type (e.g. journals) by using the method `query`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dress-chapter",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'venues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Data frame of journals\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m journals \u001b[38;5;241m=\u001b[39m \u001b[43mvenues\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjournal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m journals  \u001b[38;5;66;03m# Showing the data frame\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'venues' is not defined"
     ]
    }
   ],
   "source": [
    "# Data frame of journals\n",
    "journals = venues.query(\"type == 'journal'\")\n",
    "journals  # Showing the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-persian",
   "metadata": {},
   "source": [
    "Then, for each row in the new data frame, we retrieve the associated `internalId` of each journal by looking at the table `venueId` created above. In this case, we can use the method `merge` to accomplish the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "skilled-excellence",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m      3\u001b[0m df_joined \u001b[38;5;241m=\u001b[39m merge(journals, venues_ids, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m df_joined\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from pandas import merge\n",
    "\n",
    "df_joined = merge(journals, venues_ids, left_on=\"id\", right_on=\"id\")\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-soccer",
   "metadata": {},
   "source": [
    "Finally, the final journal table can be defined by selecting only two columns of the last merged data frame and by modifying the column name `venueId` in `internalId`, as shown as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "starting-anchor",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_joined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m journals \u001b[38;5;241m=\u001b[39m \u001b[43mdf_joined\u001b[49m[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvenueId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      2\u001b[0m journals \u001b[38;5;241m=\u001b[39m journals\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvenueId\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternalId\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      3\u001b[0m journals\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_joined' is not defined"
     ]
    }
   ],
   "source": [
    "journals = df_joined[[\"venueId\", \"name\"]]\n",
    "journals = journals.rename(columns={\"venueId\": \"internalId\"})\n",
    "journals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-advocate",
   "metadata": {},
   "source": [
    "The rename of a column is performed with the [method `rename`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html), that takes in input a dictonary with the named paramenter `columns`, where each key represent the old column name while the value is the new column name. The method returns a new data frame where the columns are renamed as specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-affair",
   "metadata": {},
   "source": [
    "A similar organisation can be provided also for books, by using the code specified above, customising it for handling books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "willing-springfield",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'venues' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Data frame of books\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m books \u001b[38;5;241m=\u001b[39m \u001b[43mvenues\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m df_joined \u001b[38;5;241m=\u001b[39m merge(books, venues_ids, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m books \u001b[38;5;241m=\u001b[39m df_joined[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvenueId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'venues' is not defined"
     ]
    }
   ],
   "source": [
    "# Data frame of books\n",
    "\n",
    "books = venues.query(\"type == 'book'\")\n",
    "df_joined = merge(books, venues_ids, left_on=\"id\", right_on=\"id\")\n",
    "books = df_joined[[\"venueId\", \"name\"]]\n",
    "books = books.rename(columns={\"venueId\": \"internalId\"})\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-planet",
   "metadata": {},
   "source": [
    "### Tables for publications\n",
    "\n",
    "Similarly, all the other tables (i.e. `JournalArticles` and `BookChapters`) can be created using the same set of operations, but starting from the [CSV document containing publications](\"../01/01-publications.csv\"). First, we create a new column with all the internal identifiers for all publications, as shown as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "essential-japanese",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m publications \u001b[38;5;241m=\u001b[39m \u001b[43mread_csv\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../01/01-publications.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      2\u001b[0m                         keep_default_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m                         dtype\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      4\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoi\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublication year\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublication venue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m                         })\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Create a new column with internal identifiers for each publication\u001b[39;00m\n\u001b[1;32m     14\u001b[0m publication_internal_id \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_csv' is not defined"
     ]
    }
   ],
   "source": [
    "publications = read_csv(\"../01/01-publications.csv\", \n",
    "                        keep_default_na=False,\n",
    "                        dtype={\n",
    "                            \"doi\": \"string\",\n",
    "                            \"title\": \"string\",\n",
    "                            \"publication year\": \"int\",\n",
    "                            \"publication venue\": \"string\",\n",
    "                            \"type\": \"string\",\n",
    "                            \"issue\": \"string\",\n",
    "                            \"volume\": \"string\"\n",
    "                        })\n",
    "\n",
    "# Create a new column with internal identifiers for each publication\n",
    "publication_internal_id = []\n",
    "for idx, row in publications.iterrows():\n",
    "    publication_internal_id.append(\"publication-\" + str(idx))\n",
    "publications.insert(0, \"internalId\", Series(publication_internal_id, dtype=\"string\"))\n",
    "publications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-lottery",
   "metadata": {},
   "source": [
    "Then, we create the table for journal articles similarly to what we have done before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "herbal-manchester",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'publications' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Data frame of journal articles\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m journal_articles \u001b[38;5;241m=\u001b[39m \u001b[43mpublications\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjournal article\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_joined \u001b[38;5;241m=\u001b[39m merge(journal_articles, venues_ids, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublication venue\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m journal_articles \u001b[38;5;241m=\u001b[39m df_joined[\n\u001b[1;32m      5\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternalId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublication year\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvenueId\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'publications' is not defined"
     ]
    }
   ],
   "source": [
    "# Data frame of journal articles\n",
    "journal_articles = publications.query(\"type == 'journal article'\")\n",
    "df_joined = merge(journal_articles, venues_ids, left_on=\"publication venue\", right_on=\"id\")\n",
    "journal_articles = df_joined[\n",
    "    [\"internalId\", \"doi\", \"publication year\", \"title\", \"issue\", \"volume\", \"venueId\"]]\n",
    "journal_articles = journal_articles.rename(columns={\n",
    "    \"publication year\": \"publicationYear\",\n",
    "    \"venueId\": \"publicationVenue\"})\n",
    "journal_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-marsh",
   "metadata": {},
   "source": [
    "Similarly, we create the table for book chapters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adequate-rachel",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'publications' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Data frame of book chapters\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m book_chapters \u001b[38;5;241m=\u001b[39m \u001b[43mpublications\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbook chapter\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_joined \u001b[38;5;241m=\u001b[39m merge(book_chapters, venues_ids, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublication venue\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m book_chapters \u001b[38;5;241m=\u001b[39m df_joined[\n\u001b[1;32m      5\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternalId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublication year\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvenueId\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'publications' is not defined"
     ]
    }
   ],
   "source": [
    "# Data frame of book chapters\n",
    "book_chapters = publications.query(\"type == 'book chapter'\")\n",
    "df_joined = merge(book_chapters, venues_ids, left_on=\"publication venue\", right_on=\"id\")\n",
    "book_chapters = df_joined[\n",
    "    [\"internalId\", \"doi\", \"publication year\", \"title\", \"venueId\"]]\n",
    "book_chapters = book_chapters.rename(columns={\n",
    "    \"publication year\": \"publicationYear\",\n",
    "    \"venueId\": \"publicationVenue\"})\n",
    "book_chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-special",
   "metadata": {},
   "source": [
    "### Adding the tables to the database\n",
    "\n",
    "As anticipated before, adding a table to a database is done, in Pandas, using the `DataFrame` method `to_sql`. This method takes in input two mandatory parameters (identifying the name of the table in the database and the database connection) plus a series of optional named parameters, among which the parameter `if_exists` that, when set to `\"replace\"`, replaces the values in an existing database table having the same name with the new data, and the parameter `index` that, when set to `False`, does not add the data frame index in the database. Thus, adding the five tables to the SQLite database created at the very beginning can be done running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suited-staff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'venues_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m connect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpublications.db\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m con:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mvenues_ids\u001b[49m\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVenueId\u001b[39m\u001b[38;5;124m\"\u001b[39m, con, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m     journals\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJournal\u001b[39m\u001b[38;5;124m\"\u001b[39m, con, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m     books\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBook\u001b[39m\u001b[38;5;124m\"\u001b[39m, con, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'venues_ids' is not defined"
     ]
    }
   ],
   "source": [
    "with connect(\"publications.db\") as con:\n",
    "    venues_ids.to_sql(\"VenueId\", con, if_exists=\"replace\", index=False)\n",
    "    journals.to_sql(\"Journal\", con, if_exists=\"replace\", index=False)\n",
    "    books.to_sql(\"Book\", con, if_exists=\"replace\", index=False)\n",
    "    journal_articles.to_sql(\"JournalArticle\", con, if_exists=\"replace\", index=False)\n",
    "    book_chapters.to_sql(\"BookChapter\", con, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-budapest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}